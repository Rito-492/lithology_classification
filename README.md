## 基于测井曲线的岩性识别与分类项目报告

#### 项目成员：tyr、fyq、yhl、hfy

### 一、项目背景

在油气勘探与开发领域，地层岩性（即岩石类型）的精确识别是资源评价、储层预测和钻井工程设计的基础。测井技术通过在钻孔中下放精密仪器，连续测量地层沿井深的各种地球物理参数（如电学、声学、放射性等），形成了丰富的测井曲线数据。这些曲线蕴含着关于地下岩石类型、物性（孔隙度、渗透率）及流体性质（油、气、水）的关键信息。

传统上，岩性识别主要依赖于地质工程师的人工解释。该方法不仅耗时耗力，而且解释结果高度依赖于个人经验，难以实现标准化和规模化。随着人工智能技术的发展，利用机器学习算法分析多维度的测井曲线，能够自动、高效、精准地识别岩性，已经成为地球物理勘探领域的研究热点。
 
本项目旨在探索和应用前沿的机器学习技术，通过分析真实的测井数据，构建一个高精度的岩性自动识别模型。这不仅能极大提升地质研究的效率和准确性，还能为油气资源的智能化勘探与开发提供坚实的技术支撑，具有重要的学术价值和广阔的工业应用前景。

### 二、项目简介

本项目使用 $\text{Python}$ 语言，基于 $Pytorch$ 框架，实现一个基于改进的 $KAN$ 网络的岩性识别模型，对给定深度点的地层岩性进行自动识别和分类，具体地是将每个深度点的岩性准确地分类为砂岩、粉砂岩、泥岩三类之一。最终的预测准确率在 $80\%$ 以上。另外，我们还尝试了 $XGBoost$ 模型，效果甚至能够达到 $90\%$。

### 三、项目结构

#### 1. 数据集

我们使用了“中国石化第一届人工智能创新大赛”官方提供的数据集。通过 $split\_val.py$ 脚本，以 $8:2$ 的块比例将数据集划分为训练集和验证集。存储于 $data$ 目录下。

我们实现了 $LogDataset$ 类，以从 $.csv$ 文件中读取数据，之后方便训练和验证流程中的数据加载。

##### 数据可视化与分析

另外，我们对原始数据首先进行了分析，并生成了可视化结果。这一部分由 ***hfy*** 完成。

在模型训练之前，我们对原始数据进行了全面的探索性分析，并生成了 $8$ 张可视化图表。数据集基本信息如下：

- **总样本数**：$38,225$ 条记录
- **特征维度**：$4$ 个测井参数（$SP$、$GR$、$AC$、$DEPTH$）
- **井数量**：$4$ 口井（井号：$2$、$146$、$298$、$2010$）
- **类别数**：$3$ 种岩性类型

通过 $\text{visualize.py}$ 脚本，我们实现了 $LithologyVisualizer$ 类，系统地生成了以下可视化结果：

**（1）类别分布分析**

![类别分布](../visualizations/01_class_distribution.png)

包含饼图和柱状图，展示三种岩性的样本分布：
- 类别 $0$（砂岩）：$9,989$ 个样本，占比 $26.13\%$
- 类别 $1$（粉砂岩）：$4,764$ 个样本，占比 $12.46\%$
- 类别 $2$（泥岩）：$23,472$ 个样本，占比 $61.40\%$

发现数据存在严重的类别不平衡问题，类别 $2$ 占据了超过 $60\%$ 的样本。

**（2）特征分布直方图**

![特征分布](../visualizations/02_feature_distributions.png)

展示四个特征的分布情况，并标注均值和中位数：
- **SP**（自然电位）：均值 $54.98$，标准差 $21.59$，范围 $[7.47, 476.40]$
- **GR**（自然伽马）：均值 $134.72$，标准差 $34.21$，范围 $[10.00, 308.10]$
- **AC**（声波时差）：均值 $293.89$，标准差 $57.23$，范围 $[120.49, 567.06]$
- **DEPTH**（深度）：均值 $1917.85$，标准差 $688.16$，范围 $[301.04, 3316.88]$

发现 $SP$ 特征存在极端异常值，最大值远大于第 $75$ 百分位数。

**（3）特征相关性热力图**

![特征相关性](../visualizations/03_correlation_matrix.png)

通过 $Pearson$ 相关系数矩阵，展示四个特征之间的线性相关关系，用于识别潜在的特征冗余和多重共线性问题。

**（4）分类别箱线图**

![分类别箱线图](../visualizations/04_boxplots_by_class.png)

针对每个岩性类别，展示各特征的分布情况（中位数、四分位距、异常值等），帮助识别哪些特征对岩性分类具有最强的判别能力。

**（5）特征散点矩阵**

![特征散点矩阵](../visualizations/05_scatter_matrix.png)

对 $SP$、$GR$、$AC$ 三个测井参数进行两两散点图绘制，对角线为各类别的直方图，非对角线为不同类别的散点分布。采样 $5000$ 个点以提高可视化效率，用于观察特征空间中的类别分布模式和聚类趋势。

**（6）测井曲线综合显示**

![测井曲线](../visualizations/06_well_logs.png)

选取样本数最多的井，展示 $200$ 米连续井段的测井曲线和岩性柱：
- 前三列：$SP$、$GR$、$AC$ 随深度变化的曲线
- 第四列：岩性柱状图（不同颜色代表不同岩性）

这种传统的测井解释图帮助理解测井响应与岩性变化的对应关系。

**（7）分井统计分析**

![分井统计](../visualizations/07_well_statistics.png)

包含四个子图：
- 各井样本数统计：井 $2$ 有 $16,776$ 个样本，井 $2010$ 仅有 $1,505$ 个样本
- 各井深度范围
- 各井岩性分布（堆叠柱状图）
- 各井岩性百分比

发现不同井之间的样本数量差异较大，但岩性分布模式基本一致。

**（8）特征随深度变化**

![特征随深度变化](../visualizations/08_feature_by_depth.png)

三个散点图展示 $SP$、$GR$、$AC$ 随深度的变化趋势，不同颜色代表不同岩性。采样 $10,000$ 个点，用于观察测井参数的深度相关性和岩性的深度分布规律。

##### 数据质量评估

基于可视化分析，我们总结出以下发现：
- 严重的类别不平衡
- $SP$ 特征存在离群值
- 不同井之间样本数差异较大

**针对性处理方案**：
1. **类别不平衡处理**：在训练过程中使用类别权重（$class\_weight$ 参数）
2. **异常值处理**：对特征进行稳健归一化

以上数据可视化与分析工作，由 ***黄方勇*** 完成。

#### 2.模型架构

首先，我们系统学习了 $\text{Kolmogorov-Arnold Network (KAN)}$ 模型的基本概念和原理。并且调研了多个开源的模型实现，最终选择参考 [efficient-kan](https://github.com/Blealtan/efficient-kan) 的实现。

传统的全连接层在高维数据上容易受到激活函数的限制，并且难以灵活地拟合复杂的非线性关系。而 $KAN$ 用可学习的 $B$ 样条函数替代了传统神经网络的固定激活函数。每个 $\text{KANLayer}$ 层实际上是在学习最优的激活函数形状，而不仅仅是权重参数。我们参考的 $\text{efficient-kan}$ 模型中，对 $KAN$ 的原始实现做了一些改进，先用不同的基函数激活输入，然后将它们线性组合。最后的核心公式如下：
$$
y = W_{\text {base}} \sigma(x) + W_{\text {spline}} B(x)
$$
其中:
- $ \sigma(\cdot) $ 是 $Sigmoid$ 激活函数;
- $ B(x) $ 是基于 $\text{B-splines}$ 的非线性基函数，由controlled by grid nodes and spline order;
- $ W_{\text {base}} $ and $ W_{\text {spline}} $ 为可学习权重。

关于损失函数的计算，我们使用 $\text{CrossEntropyLoss}$ 函数加上 $KAN$ 的正则化损失，并使用 $\text{Adam}$ 优化器进行训练。并且在训练过程中，我们启用了自适应网格更新，以适应数据分布的变化。

以上关于模型架构的实现，由 ***tyr*** 参考 [efficient-kan](https://github.com/Blealtan/efficient-kan) 完成。

#### 3.模型改进

此外我们基于以上的模型进行了改进，采用了残差连接机制来增强网络的学习能力。具体来说，在 $KAN$ 类的 $\text{forward}$ 方法中实现了以下机制：
``` python
    def forward(self, x: torch.Tensor, update_grid=False):
        curr = 4
        resi = torch.tensor([0, 0, 0, 0]).to(self.device)
        flag = False
        x = x.to(self.device)
        for layer, hid in zip(self.layers, self.layer_hidden[1:]):
            if update_grid:
                layer.update_grid(x)
            if curr == hid:
                x = layer(x)
                if flag:
                    resi = x.to(self.device)
                    flag=  False
            else:
                x = layer(x + resi)
                curr = hid
                flag = True
        return x
```

该前向传播机制的核心思想如下：

- 残差连接机制：通过引入残差张量 `resi`，在网络层之间传递信息，帮助缓解深层网络训练中的梯度消失问题。
- 动态残差更新：使用 curr 变量跟踪当前层的输出维度，当维度发生变化时(` curr != hid `)，将残差添加到输入中，并更新当前维度。
- 条件网格更新：通过 `update_grid` 参数控制是否在前向传播过程中更新B样条的网格点，这有助于适应输入数据的分布变化。

这种设计使得模型能够更好地学习测井数据中的复杂关系，同时保持训练的稳定性。在网络较深的情况下，残差连接能够帮助信息更好地流动，从而提高模型的表达能力和泛化性能。

模型改进的实现，由 ***fyq*** 完成。

#### 4.另外的探索

在尝试了 $KAN$ 之后，我们还尝试了 $XGBoost$ 模型，效果甚至能够达到 $90\%$。

我们的测井数据是典型的结构化表格数据，特征维度低（仅 `DEPTH`, `SP`, `GR`, `AC` 四项），但每个特征具有明确的地球物理意义，且数据完整无缺失。这类数据非常适合 $XGBoost$ 这类基于决策树的集成模型。

$XGBoost$ 无需对特征进行标准化或归一化，因为它基于特征值的相对大小进行节点分裂，直接使用原始物理量即可。这不仅简化了预处理流程，也保留了特征的可解释性。更重要的是，$XGBoost$ 能自动学习特征间的非线性关系和组合规则（如“高 $GR$ 与低 $AC$ 可能共同指示泥岩”），无需人工构造复杂特征。其内置的正则化（L1/L2）和子采样机制有效防止了过拟合，特别适合本任务中样本量有限但模式复杂的情况。

$XGBoost$ 采用加法训练框架，每一轮迭代学习一棵新树 $f_t$ 来拟合当前残差。第 $t$ 轮的目标函数为：
$$
\mathcal{L}^{(t)} = \sum_{i=1}^{n} l\left(y_i, \hat{y}_i^{(t-1)} + f_t(x_i)\right) + \Omega(f_t)
$$
其中 $\hat{y}_i^{(t-1)}$ 是前 $t-1$ 棵树的累加预测值，$\Omega(f_t)$ 为树的复杂度惩罚：
$$
\Omega(f_t) = \gamma T + \frac{1}{2} \lambda \sum_{j=1}^{T} w_j^2
$$
$T$ 为叶子节点数，$w_j$ 为第 $j$ 个叶子的权重，$\gamma$ 和 $\lambda$ 为正则化超参数。

在训练时，使用二阶泰勒展开近似损失函数：
$$
l(y_i, \hat{y}_i^{(t-1)} + f_t(x_i)) \approx g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)
$$
其中 $g_i, h_i$ 为损失函数关于当前预测值的一阶和二阶梯度。基于此，选择使以下增益最大的特征和切分点进行分裂：
$$
\text{Gain} = \frac{1}{2} \left( \frac{G_L^2}{H_L + \lambda} + \frac{G_R^2}{H_R + \lambda} - \frac{(G_L + G_R)^2}{H_L + H_R + \lambda} \right) - \gamma
$$
其中 $G_L, H_L$ 和 $G_R, H_R$ 分别为左、右子节点的梯度和海赛统计量之和，$(G_L + G_R)^2 / (H_L + H_R + \lambda)$ 表示分裂前的损失分数。

实验中，我们使用 `GridSearchCV` 对 `n_estimators`, `max_depth`, `learning_rate` 等关键参数进行调优，以 `f1_macro` 为评分标准。

以下是核心参数搜索空间：

```python
param_grid = {
    'n_estimators': [200, 300, 400],
    'max_depth': [5, 6, 7, 8],
    'learning_rate': [0.03, 0.05, 0.1],
    'reg_lambda': [0.5, 1.0, 2.0, 3.0],
    'gamma': [0.0, 0.1, 0.2],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}
```
最终模型在测试集上取得了超过 $90\%$ 的准确率，且采用 `gain` 模式计算的特征重要性显示 $GR$贡献最大，符合地质学常识，说明模型学到了合理的判别逻辑。

本部分，由 ***yhl*** 完成。

### 四、模型效果

#### 1.原始 $\text{efficient-kan}$ 模型

分类报告:
| precision | recall | f1-score | support |
|:-:|:-:|:-:|:-:|
| 粉砂岩 | 0.7176 | 0.7187 | 0.7182 | 1998 |
| 砂岩 | 0.5824 | 0.8940 | 0.7053 | 953 |
| 泥岩 | 0.8852 | 0.7885 | 0.8340 | 4694 |

| accuracy | | | 0.7834 | 7645 |
|:-:|:-:|:-:|:-:|:-:|
| macro avg | 0.7284 | 0.8004 | 0.7525 | 7645 |
|weighted avg | 0.8037 | 0.7834 | 0.7877 | 7645 |

最终准确率为 $78.34\%$

#### 2.基于 $\text{efficient-kan}$ 模型的改进

分类报告:
| precision | recall | f1-score | support |
|:-:|:-:|:-:|:-:|
| 粉砂岩 | 0.7232 | 0.7518 | 0.7372 | 1998 |
| 砂岩 | 0.6255 | 0.8814 | 0.7317 | 953 |
| 泥岩 | 0.9011 | 0.8110 | 0.8537 | 4694 |

| accuracy | | | 0.8043 | 7645 |
|:-:|:-:|:-:|:-:|:-:|
| macro avg | 0.7499 | 0.8147 | 0.7742 | 7645 |
|weighted avg | 0.8202 | 0.8043 | 0.8080 | 7645 |

最终准确率为 $78.34\%$

#### 3.另外探索的 $\text{XGBoost}$ 模型


### 五、项目总结

#### 1. 技术实现方面
本次项目，我们成功实现了一个基于 $\text{KAN}$ 的岩性识别模型，并尝试了使用 $\text{XGBoost}$ 的模型。
我们成功地将KAN网络应用于岩性识别任务，构建了一个有效的深度学习模型。通过对 $\text{effective-kan}$ 开源实现的研究和改进，我们不仅掌握了 $\text{KAN}$ 网络的核心原理，还针对测井数据的特点进行了针对性优化。在模型实现过程中，我们还引入了残差连接机制和正则化技术，有效提升了模型的训练稳定性和泛化能力。

#### 2. 实验结果与对比
通过与传统机器学习方法 $\text{XGBoost}$ 的对比实验，我们发现虽然 $\text{XGBoost}$ 在本任务中能达到约 $90\%$ 的准确率，但基于 $\text{KAN}$ 的深度学习方法具有更好的可解释性和理论优势。 $\text{KAN}$ 网络通过学习可解释的激活函数，为我们提供了洞察测井数据内在规律的可能性，这是传统黑盒模型难以提供的。

#### 3. 项目挑战与收获
在项目实施过程中，我们也遇到了诸多挑战。首先是 $\text{KAN}$ 网络作为一种新兴的神经网络架构，相关资料和成熟应用案例较少，需要我们深入理解其数学原理并自行调试优化。其次是测井数据的复杂性和不平衡性给模型训练带来了困难，我们通过类别权重平衡和正则化技术有效缓解了这一问题。

通过本项目，我们不仅加深了对深度学习理论的理解，也提高了实际工程项目的能力。特别是在数据预处理、模型设计、训练调优和结果分析等方面积累了宝贵的经验。

#### 4. 不足之处
本项目中，我们并未深入研究 $\text{KAN}$ 的可解释性。传统的深度学习模型往往是无法解释其输出结果的黑箱模型，而 $\text{KAN}$ 则通过学习可解释的激活函数，为用户提供更加直观的对数据的诠释。然而，由于时间原因，我们并未在这方面做过多探索和研究，或许如果充分利用 $\text{KAN}$ 网络的这一优势，就能更深入挖掘学习到的激活函数背后的地质意义，为地质解释提供更有力的支持。